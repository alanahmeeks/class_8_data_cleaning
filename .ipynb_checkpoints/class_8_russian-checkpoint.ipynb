{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5d15584",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae859ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cefc91f4",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'sberbank-russian-housing-market/train.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/h8/3v6snfqs35s2z7kjthv7z9wm0000gn/T/ipykernel_74630/2745837033.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"sberbank-russian-housing-market/train.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    227\u001b[0m             \u001b[0mmemory_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m             \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"encoding_errors\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"strict\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m         )\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    705\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 707\u001b[0;31m                 \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    708\u001b[0m             )\n\u001b[1;32m    709\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'sberbank-russian-housing-market/train.csv'"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"sberbank-russian-housing-market/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f135f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db81705d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2767ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655cf931",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b83a026",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols=df.select_dtypes(include=['number']).columns\n",
    "\n",
    "print(numeric_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad15f8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_numeric_cols=df.select_dtypes(exclude=['number']).columns\n",
    "\n",
    "print(non_numeric_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e644518",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[non_numeric_cols].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79073fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_missing=df.isna().sum()\n",
    "\n",
    "num_missing[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b765654b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pct_missing = df.isna().mean()\n",
    "\n",
    "pct_missing[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "588b3130",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bfbf381",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b365dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = df.columns[:30]\n",
    "\n",
    "colors = ['#000099','#ffff00'] \n",
    "sns.heatmap(df[cols].isna(), cmap=sns.color_palette(colors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdefc1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import missingno as msno - library not found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4ba67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_by_row = df.isna().sum(axis='columns')\n",
    "\n",
    "missing_by_row.hist(bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5633124d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len_missing=num_missing[num_missing>0]\n",
    "\n",
    "print(len(len_missing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70432226",
   "metadata": {},
   "outputs": [],
   "source": [
    "len_missing[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dadf942b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pct_missing[pct_missing>.3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1619e526",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_less_missing_cols = df.loc[:, pct_missing <= .3].copy()\n",
    "\n",
    "df_less_missing_cols.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988a3428",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_less_missing_rows = df[missing_by_row<35].copy()\n",
    "\n",
    "df_less_missing_rows.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d967190f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy = df.copy()\n",
    "\n",
    "df_copy[numeric_cols] = df_copy[numeric_cols].fillna(-999)\n",
    "\n",
    "df_copy[non_numeric_cols] = df_copy[non_numeric_cols].fillna('_MISSING_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22dabb57",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy2 = df.copy()\n",
    "med = df_copy2[numeric_cols].median()\n",
    "\n",
    "df_copy2[numeric_cols] = df_copy2[numeric_cols].fillna(med)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8738f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "most_freq = df_copy2[non_numeric_cols].describe().loc['top']\n",
    "most_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c351c9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy2[non_numeric_cols]=df_copy2[non_numeric_cols].fillna(most_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299ecc16",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Method 1 for identifying Outliers\n",
    "#Kurtosis\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aeea24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.kurt(numeric_only=True)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e70e0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['life_sq'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ecce0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Method 2, histogram and box plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43261909",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['life_sq'].hist(bins=100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a62efb6f",
   "metadata": {},
   "source": [
    "Can see that the data is highly skewed, with possible outliers.\n",
    "\n",
    "But due to low frequency, cant see th exact location of the outliers and the counts\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e92bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.boxplot(column=['life_sq'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d53631",
   "metadata": {},
   "source": [
    "Boxplot gives a more clear view of the outliers. There is an outlier with a value of over 7,000.\n",
    "All the dots on the plot are considered outliers by the box plot definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89269a1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fce071ee",
   "metadata": {},
   "source": [
    "Method #3 - Bar chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1811560d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ecology'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e54646b9",
   "metadata": {},
   "source": [
    "Has even distribution. But if there is a category with only one value called \"Extraordinary' that could be considered an outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e3cfc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e6e27287",
   "metadata": {},
   "source": [
    "UNNECESSARY DATA TYPE 1: Repetitive and uniformative\n",
    "\n",
    "\n",
    "If there is a column with an extremely high percentage of the same value. investigate for value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4587f675",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rows=len(df)\n",
    "\n",
    "\n",
    "\n",
    "for col in df.columns:\n",
    "    cnts=df[col].value_counts(dropna=False)\n",
    "    top_pct = (cnts/num_rows).iloc[0] #gives largest value count location\n",
    "    \n",
    "    if top_pct > 0.999:\n",
    "        print('{0} : {1:.2f}%'.format(col, top_pct*100))\n",
    "        \n",
    "        print(cnts)\n",
    "        \n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70fae5b8",
   "metadata": {},
   "source": [
    "Specifying to show columns with over 99.9% rows being the same value. no such row exists. Don't understand any of what it was doing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e296ef66",
   "metadata": {},
   "source": [
    "If there is a column with a high percentage of the same value, we should look into it to see if its informative. can drop them when they are not / when the column is 100% the same value\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb742c3",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "UNNECESSARY TYPE 2: IRRELEVANT\n",
    "Scan through info, find irrelevant features. could use .drop in PANDAS to remove them"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dddcf49",
   "metadata": {},
   "source": [
    "UNNECESSARY TYPE 3: DUPLICATES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db9bc07",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Duplicate Type 1, All columns based\n",
    "\n",
    "df[df.duplicated()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d757eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Duplicates type #2: Key Columns based\n",
    "#Drop column id and see if there are duplicates based on the\n",
    "#rest of the columns. \n",
    "# First we drop id and then see if there are duplicated rows \n",
    "# from the DataFrame\n",
    "\n",
    "\n",
    "df[df.drop(columns=['id']).duplicated()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0d064c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dedupped = df.drop(columns=['id']).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046cdc33",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape)\n",
    "print(df_dedupped.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df81bd19",
   "metadata": {},
   "source": [
    "Removes the 10 rows of duplicates. Had to drop the \"id\" column, as it was likely unique for each entry. This shows the rest as what is actually duplicated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3785258f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4504d599",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = ['timestamp', 'full_sq', 'life_sq', 'floor', 'build_year', 'num_room', 'price_doc']\n",
    "\n",
    "df_grouped = df.fillna(-999).groupby(key)['id'].count()\n",
    "\n",
    "df_grouped[df_grouped > 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de1027da",
   "metadata": {},
   "source": [
    "We can drop these duplicates based on the subset of key columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4cea9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dedupped2=df.drop_duplicates(subset=key)\n",
    "\n",
    "print(df.shape)\n",
    "\n",
    "print(df_dedupped2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ae105b",
   "metadata": {},
   "source": [
    "INCONSISTENT DATA\n",
    "type 1, capitilization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136c2cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sub_area'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8ef45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make them all upper or lower to ensure consistency \n",
    "df['sub_area_lower']=df['sub_area'].str.lower()\n",
    "df['sub_area_lower'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e9f473c",
   "metadata": {},
   "source": [
    "Type 2: Data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d49fc1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['timestamp']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3f2868",
   "metadata": {},
   "source": [
    "Has a dtype of object. Can convert to a DateTime format and be able to extract the specific year, month, weekday etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f55305",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['timestamp_dt'] = pd.to_datetime(df['timestamp'], format='%Y-%m-%d')\n",
    "\n",
    "df['year'] = df['timestamp_dt'].dt.year\n",
    "\n",
    "df['month']= df['timestamp_dt'].dt.month\n",
    "\n",
    "df['weekday'] = df['timestamp_dt'].dt.weekday\n",
    "\n",
    "\n",
    "df[['timestamp_dt', 'year', 'month', 'weekday']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "809a7804",
   "metadata": {},
   "source": [
    "TYPE 3: typos of categorical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1f1fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate a new DataFram, df_city_ex, with only one column \n",
    "# that stores the city names\n",
    "\n",
    "df_city_ex=pd.DataFrame(data={'city' : ['torontoo', 'toronto', 'tronto', 'vancouver', 'vancover', 'vancouvr', 'montreal', 'calgary']})\n",
    "\n",
    "cities = ['toronto', 'vancouver', 'montreal', 'calgary']\n",
    "\n",
    "from nltk.metrics import edit_distance\n",
    "\n",
    "for city in cities:\n",
    "    df_city_ex[f'city_distance_{city}'] = df_city_ex['city'].map(lambda x: edit_distance(x, city))\n",
    "    \n",
    "df_city_ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e721c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "msk = df_city_ex['city_distance_toronto'] <=2\n",
    "df_city_ex.loc[msk, 'city'] = 'toronto'\n",
    "\n",
    "\n",
    "msk=df_city_ex['city_distance_vancouver']<=2\n",
    "df_city_ex.loc[msk, 'city'] = 'vancouver'\n",
    "\n",
    "df_city_ex"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc89bf2e",
   "metadata": {},
   "source": [
    "TYPE 4: Addresses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46545ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_add_ex = pd.DataFrame(['123 MAIN St Apartment 15', '123 Main Street Apt 12  ', '543 FIRst Av', '876 FirSt Ave.'], columns=['address'])\n",
    "\n",
    "df_add_ex"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da17540e",
   "metadata": {},
   "source": [
    "Run code to \n",
    "- lowercase the letters\n",
    "- remove leading and trailing white spaces\n",
    "- delete periods\n",
    "- standarize wordings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1e3b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_add_ex['address_std'] = df_add_ex['address'].str.lower()\n",
    "df_add_ex['address_std'] = df_add_ex['address_std'].str.strip()\n",
    "#removes ^ leading and trailing whitespace\n",
    "\n",
    "df_add_ex['address_std'] = df_add_ex['address_std'].str.replace('\\\\.', '', regex=True)\n",
    "#removes^ period\n",
    "\n",
    "df_add_ex['address_std'] = df_add_ex['address_std'].str.replace('\\\\bstreet\\\\b', 'st', regex=True)\n",
    "#replace street with st\n",
    "\n",
    "df_add_ex['address_std'] = df_add_ex['address_std'].str.replace('\\\\bapartment\\\\b','apt', regex=True)\n",
    "#replace apartment with apt\n",
    "\n",
    "df_add_ex['address_std'] = df_add_ex['address_std'].str.replace('\\\\bav\\\\b', 'ave', regex=True)\n",
    "#replace av with ave\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed970bf5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_add_ex"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6fccadf",
   "metadata": {},
   "source": [
    "https://www.justintodata.com/data-cleaning-techniques-python-guide/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "046d9cbe",
   "metadata": {},
   "source": [
    "Used regular expressions to specify search patterns\n",
    "https://docs.python.org/3/library/re.html\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4123e552",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e1857b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aafde374",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
